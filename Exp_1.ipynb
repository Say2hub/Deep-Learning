{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step function and perceptron model"
      ],
      "metadata": {
        "id": "KWYulJ9SFtm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def unitStep(v):\n",
        "    return 1 if v >= 0 else 0\n",
        "\n",
        "def perceptronModel(x, w, b):\n",
        "    v = np.dot(w, x) + b\n",
        "    y = unitStep(v)\n",
        "    return y"
      ],
      "metadata": {
        "id": "uZJN4Nyv8vd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AND logic function using a perceptron"
      ],
      "metadata": {
        "id": "xExUnr-q86uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AND_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -1.5\n",
        "    return perceptronModel(x, w, b), w, b\n",
        "\n",
        "\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "\n",
        "outputs = [\n",
        "    (\"AND(0, 1)\", AND_logicFunction(test1)),\n",
        "    (\"AND(1, 1)\", AND_logicFunction(test2)),\n",
        "    (\"AND(0, 0)\", AND_logicFunction(test3)),\n",
        "    (\"AND(1, 0)\", AND_logicFunction(test4))\n",
        "]\n",
        "\n",
        "for description, (output, weights, bias) in outputs:\n",
        "    print(f\"{description} = {output} (Weights: {weights}, Bias: {bias})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dv5HO5I8vaB",
        "outputId": "3058a7a6-c749-4af0-8743-37be474735e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(0, 1) = 0 (Weights: [1 1], Bias: -1.5)\n",
            "AND(1, 1) = 1 (Weights: [1 1], Bias: -1.5)\n",
            "AND(0, 0) = 0 (Weights: [1 1], Bias: -1.5)\n",
            "AND(1, 0) = 0 (Weights: [1 1], Bias: -1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OR logic function using a perceptron"
      ],
      "metadata": {
        "id": "uQGwAFXm9KMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def OR_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -0.5\n",
        "    return perceptronModel(x, w, b), w, b\n",
        "\n",
        "\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "\n",
        "outputs = [\n",
        "    (\"OR(0, 1)\", OR_logicFunction(test1)),\n",
        "    (\"OR(1, 1)\", OR_logicFunction(test2)),\n",
        "    (\"OR(0, 0)\", OR_logicFunction(test3)),\n",
        "    (\"OR(1, 0)\", OR_logicFunction(test4))\n",
        "]\n",
        "\n",
        "\n",
        "for description, (output, weights, bias) in outputs:\n",
        "    print(f\"{description} = {output} (Weights: {weights}, Bias: {bias})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3szTkRuu7ij",
        "outputId": "3c399f31-33bd-458c-f2e3-3da55763e212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR(0, 1) = 1 (Weights: [1 1], Bias: -0.5)\n",
            "OR(1, 1) = 1 (Weights: [1 1], Bias: -0.5)\n",
            "OR(0, 0) = 0 (Weights: [1 1], Bias: -0.5)\n",
            "OR(1, 0) = 1 (Weights: [1 1], Bias: -0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOT logic function using a perceptron"
      ],
      "metadata": {
        "id": "gY3Vwur59PUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def NOT_logicFunction(x):\n",
        "    w = -1\n",
        "    b = 0.5\n",
        "    return perceptronModel(x, w, b), w, b\n",
        "\n",
        "\n",
        "test1 = np.array(1)\n",
        "test2 = np.array(0)\n",
        "\n",
        "outputs = [\n",
        "    (\"NOT(1)\", NOT_logicFunction(test1)),\n",
        "    (\"NOT(0)\", NOT_logicFunction(test2))\n",
        "]\n",
        "\n",
        "for description, (output, weight, bias) in outputs:\n",
        "    print(f\"{description} = {output} (Weight: {weight}, Bias: {bias})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBn89kTR6AtQ",
        "outputId": "bf21a64b-9d39-482a-e89c-186713ced0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT(1) = 0 (Weight: -1, Bias: 0.5)\n",
            "NOT(0) = 1 (Weight: -1, Bias: 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# NAND logic function using AND and NOT gates"
      ],
      "metadata": {
        "id": "CrKr5fqP9S1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def AND_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    bAND = -1.5\n",
        "    return perceptronModel(x, w, bAND), w, bAND\n",
        "\n",
        "\n",
        "def NOT_logicFunction(x):\n",
        "    wNOT = -1\n",
        "    bNOT = 0.5\n",
        "    return perceptronModel(x, wNOT, bNOT), wNOT, bNOT\n",
        "\n",
        "def NAND_logicFunction(x):\n",
        "    output_AND, w_AND, b_AND = AND_logicFunction(x)\n",
        "    output_NOT, w_NOT, b_NOT = NOT_logicFunction(output_AND)\n",
        "    return output_NOT, (w_AND, b_AND), (w_NOT, b_NOT)\n",
        "\n",
        "test_cases = [\n",
        "    (0, 1),\n",
        "    (1, 1),\n",
        "    (0, 0),\n",
        "    (1, 0)\n",
        "]\n",
        "\n",
        "for x1, x2 in test_cases:\n",
        "    x = np.array([x1, x2])\n",
        "    output_NAND, (w_AND, b_AND), (w_NOT, b_NOT) = NAND_logicFunction(x)\n",
        "    print(f\"NAND({x1}, {x2}) = {output_NAND}\")\n",
        "\n",
        "print(\"\\nFinal weights and biases:\")\n",
        "print(f\"Weights for AND: {w_AND}, Bias for AND: {b_AND}\")\n",
        "print(f\"Weight for NOT: {w_NOT}, Bias for NOT: {b_NOT}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebbsHgsY6CSM",
        "outputId": "3fb0ea63-2d77-49b3-f45f-58d644e04207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAND(0, 1) = 1\n",
            "NAND(1, 1) = 0\n",
            "NAND(0, 0) = 1\n",
            "NAND(1, 0) = 1\n",
            "\n",
            "Final weights and biases:\n",
            "Weights for AND: [1 1], Bias for AND: -1.5\n",
            "Weight for NOT: -1, Bias for NOT: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOR logic function using OR and NOT gate"
      ],
      "metadata": {
        "id": "QZ7JVnu39WKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def NOT_logicFunction(x):\n",
        "    wNOT = -1\n",
        "    bNOT = 0.5\n",
        "    return perceptronModel(x, wNOT, bNOT), wNOT, bNOT\n",
        "\n",
        "\n",
        "def OR_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    bOR = -0.5\n",
        "    return perceptronModel(x, w, bOR), w, bOR\n",
        "\n",
        "\n",
        "def NOR_logicFunction(x):\n",
        "    output_OR, w_OR, b_OR = OR_logicFunction(x)\n",
        "    output_NOT, w_NOT, b_NOT = NOT_logicFunction(output_OR)\n",
        "    return output_NOT, (w_OR, b_OR), (w_NOT, b_NOT)\n",
        "\n",
        "\n",
        "test_cases = [\n",
        "    (0, 1),\n",
        "    (1, 1),\n",
        "    (0, 0),\n",
        "    (1, 0)\n",
        "]\n",
        "\n",
        "\n",
        "for x1, x2 in test_cases:\n",
        "    x = np.array([x1, x2])\n",
        "    output_NOR, (w_OR, b_OR), (w_NOT, b_NOT) = NOR_logicFunction(x)\n",
        "    print(f\"NOR({x1}, {x2}) = {output_NOR}\")\n",
        "\n",
        "print(\"\\nFinal weights and biases:\")\n",
        "print(f\"Weights for OR: {w_OR}, Bias for OR: {b_OR}\")\n",
        "print(f\"Weight for NOT: {w_NOT}, Bias for NOT: {b_NOT}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ_YXAYK7Uqg",
        "outputId": "cd257fac-4cba-432b-f048-bf706ffe816a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOR(0, 1) = 0\n",
            "NOR(1, 1) = 0\n",
            "NOR(0, 0) = 1\n",
            "NOR(1, 0) = 0\n",
            "\n",
            "Final weights and biases:\n",
            "Weights for OR: [1 1], Bias for OR: -0.5\n",
            "Weight for NOT: -1, Bias for NOT: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # XOR logic function using AND, OR, and NOT gates"
      ],
      "metadata": {
        "id": "6eG5YTkj9Z4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def unitStep(v):\n",
        "    return 1 if v >= 0 else 0\n",
        "\n",
        "def perceptronModel(x, w, b):\n",
        "    v = np.dot(w, x) + b\n",
        "    y = unitStep(v)\n",
        "    return y\n",
        "\n",
        "def NOT_logicFunction(x):\n",
        "    wNOT = -1\n",
        "    bNOT = 0.5\n",
        "    return perceptronModel(x, wNOT, bNOT), wNOT, bNOT\n",
        "\n",
        "\n",
        "def AND_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    bAND = -1.5\n",
        "    return perceptronModel(x, w, bAND), w, bAND\n",
        "\n",
        "\n",
        "def OR_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    bOR = -0.5\n",
        "    return perceptronModel(x, w, bOR), w, bOR\n",
        "\n",
        "\n",
        "def XOR_logicFunction(x):\n",
        "    y1, w_AND1, b_AND1 = AND_logicFunction(x)\n",
        "    y2, w_OR, b_OR = OR_logicFunction(x)\n",
        "    y3, w_NOT, b_NOT = NOT_logicFunction(y1)\n",
        "    final_x = np.array([y2, y3])\n",
        "    finalOutput, w_AND2, b_AND2 = AND_logicFunction(final_x)\n",
        "    return finalOutput, (w_AND1, b_AND1), (w_OR, b_OR), (w_NOT, b_NOT), (w_AND2, b_AND2)\n",
        "\n",
        "test_cases = [\n",
        "    (0, 1),\n",
        "    (1, 1),\n",
        "    (0, 0),\n",
        "    (1, 0)\n",
        "]\n",
        "\n",
        "\n",
        "for x1, x2 in test_cases:\n",
        "    x = np.array([x1, x2])\n",
        "    output_XOR, (w_AND1, b_AND1), (w_OR, b_OR), (w_NOT, b_NOT), (w_AND2, b_AND2) = XOR_logicFunction(x)\n",
        "    print(f\"XOR({x1}, {x2}) = {output_XOR}\")\n",
        "\n",
        "print(\"\\nFinal weights and biases for XOR logic:\")\n",
        "print(f\"Weights for first AND: {w_AND1}, Bias for first AND: {b_AND1}\")\n",
        "print(f\"Weights for OR: {w_OR}, Bias for OR: {b_OR}\")\n",
        "print(f\"Weight for NOT: {w_NOT}, Bias for NOT: {b_NOT}\")\n",
        "print(f\"Weights for second AND: {w_AND2}, Bias for second AND: {b_AND2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNv6miOc74cr",
        "outputId": "d9eb465f-f947-45d1-c388-26ddf7c93759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n",
            "\n",
            "Final weights and biases for XOR logic:\n",
            "Weights for first AND: [1 1], Bias for first AND: -1.5\n",
            "Weights for OR: [1 1], Bias for OR: -0.5\n",
            "Weight for NOT: -1, Bias for NOT: 0.5\n",
            "Weights for second AND: [1 1], Bias for second AND: -1.5\n"
          ]
        }
      ]
    }
  ]
}